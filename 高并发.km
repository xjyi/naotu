{"root":{"data":{"id":"bx8b4ie4xs00","created":1569335836142,"text":"高并发"},"children":[{"data":{"id":"bx8b4r2ulns0","created":1569335855051,"text":"MQ","layout":null,"expandState":"collapse"},"children":[{"data":{"id":"bx8b8mdmtt40","created":1569336158276,"text":"为什么要使用MQ","note":"* 业务场景遇到什么技术挑战\n\t* 如果不用会很麻烦\n    \t* 但是用MQ就可以很好的处理\n        \n    * 适合场景\n    \t* 解耦\n        * 异步\n        * 削峰\n \n* 解耦\n\t* 系统对接多个系统\n    \t* 多套接口\n        \n    * 使用MQ，需要消息的就去获取\n    \t* 生产者消费者解耦\n        \n    * 场景\n    \t* 待补充\n\n\n* 异步\n\t* 一般互联网接口要求响应时间200ms以内\n    \t* 一个接口如果调用其他多个系统\n        * 总耗时可能长达1s，则性能太差\n    * 此时可以用MQ做异步处理\n    \t* 发送到MQ的时长很短，不需要等系统响应\n        \n        \n* 削峰\n\t* 5000QBS属于高并发（约100万用户）\n    \t* mysql一般能扛到2000个请求每秒\n        * 一万用户在线，50qbs也是正常的\n   \n   * 用户请求到达系统前，先用mq存储","layout":null},"children":[]},{"data":{"id":"bx95923cvjs0","created":1569420825780,"text":"优缺点","note":"* 优点\n\t* 见“为什么使用”\n    \n* 缺点\n\t* 系统可用性降低\n    \t* MQ故障\n        * 解决:钉钉预警\n    \n    * 系统复杂性提高\n    \t* 数据发送了多次\n        * 解决：接口的幂等性（请求流水号）\n        \n        \n        * 消息丢了/顺序乱了\n    \n    * 一致性问题\n    \t* 某一个MQ执行失败\n    \n","layout":null},"children":[]},{"data":{"id":"bx8bdi39oq80","created":1569336540763,"text":"技术选型","note":"* 中小型公司用rabbitMQ\n\n* 大公司用rocketMQ\n\t* 性能各方面做的很好\n    * 大公司有能力维护rocket源码\n    \n\n* 大数据领域（实时计算）、数据采集\n\t* kafaka是业内标准，规范","expandState":"collapse","layout":null},"children":[{"data":{"id":"bx95styjopc0","created":1569422375358,"text":"activeMQ","note":"1. activeMQ\n\t* 单机吞吐量 万级\n    \t* 每秒处理数据量\n    * 时效性\n    \t* 毫秒ms\n    * 可用性 高\n    \t* 基于主从架构\n    * 消息可靠性\n    \t* 较低概率丢失数据\n        \n \n* 总结\n\t* 技术成熟\n    \t* 出了很久了（以前mq技术首选）\n        \n    * 缺点\n    \t* 有较低概率丢数据\n      \t* 官方社区不活跃\n        * 较少用在大规模吞吐的场景","layout":null},"children":[]},{"data":{"id":"bx95t04j1p40","created":1569422388781,"text":"rabbitMQ","note":"2. rabbitMQ\n\t* 单机吞吐量 万级\n    * 时效性（最大优点，低延迟）\n    \t* 微秒\n    * 可用性 高\n    \t* 基于主从架构\n        \n\n* 总结\n\t* 基于erlang开发\n    \t* 并发能力强，性能好，延时低\n        * 即消息在mq内部处理的时间少\n        * 此优点不明显\n        * 源码不好阅读\n    * 管理界面友好，中小型公司多使用\n    * 社区相对活跃","layout":null},"children":[]},{"data":{"id":"bx95t5gijco0","created":1569422400389,"text":"rocketMQ","note":"3. rocketMQ\n\t* 单机吞吐量 十万级\n    * 时效性\n    \t* 毫秒ms\n    * 可用性非常高\n    \t* 分布式架构\n\n* 总结\n\t* topic 增加到几百上千时\n    \t* 吞吐量有小幅下降\n    * 阿里开源，品质保障\n    \t* java语言\n    * 社区活跃度尚可\n    \n    * 公司假如不再维护，会有较大坏影响","layout":null},"children":[]},{"data":{"id":"bx95tdzbojk0","created":1569422418941,"text":"kafka","note":"\n4. kafka\n\t* 单机吞吐量 十万级（最大优点，吞吐量高）\n    \t* 一般配合大数据类的系统进行实时数据计算，日志采集\n        \n    * 时效性\n    \t* 毫秒ms\n        \n    * 可用性非常高\n    \t* 分布式架构，一个数据多个副本\n        * 少数机器宕机，不丢失数据，不会导致不可用\n        \n* 总结\n\t* topic较多时（上百）\n    \t* 性能下降较快\n        \n    * 只能支持简单的MQ功能\n    \t","layout":null},"children":[]}]},{"data":{"id":"bx9zoi4swdc0","created":1569506669456,"text":"如何 保证消息队列的高可用","note":null,"expandState":"expand","layout":null},"children":[{"data":{"id":"bxa0caftac80","created":1569508533447,"text":"rabbitMQ","note":"* rabbitMQ\n\t* 非分布式\n    * 有集群\n    \t* 单机模式\n        * 普通集群模式\n        * [镜像集群模式]\n\n* 开启镜像集群模式\n\t* 管理后台新增一个策略\n    \t* 即该策略\n    * 可以要求数据同步到所有节点\n    \t* 也可以要求同步到指定数量节点\n        \n* 普通集群\n\t* 创建的 每一个队列，只会保存在其中一个节点（机器上）\n    \t* 该节点包含了元数据、实际的数据\n        * 元数据即是一些配置信息，如结构、名称等\n        * 其他节点上保存的是队列的元数据，以及有实际数据的节点位置\n    \n    \n    * 消费者去到没有数据的节点拿数据，则该节点会去有数据的节点拉取\n    \t* 可能导致mq内部大量数据传输\n    \n    \n    * 可以提高消费吞吐量\n    \t* 可用性几乎没有保障\n        * 存数据的节点宕机，则无法消费\n        \n* 镜像集群模式\n\t* 支持高可用\n    \t* 一个节点挂了，其他节点还有数据\n    * 队列的元数据、数据在每个节点上都有\n    \t* 写入数据的节点会对其他节点进行同步\n    * 非分布式\n    \t* 数据量达到单机承受布不了的话会有问题","layout":null},"children":[]},{"data":{"id":"bxa0hwtc5co0","created":1569508973975,"text":"kafka","note":"* 分布式\n\t* 每台机器（节点）有一个broker进程\n    \t* 每台机器+机器上的broker进程，就是kafka集群中的一个基点\n    \n    * 创建一个topic\n    \t* topic会被分成多个partition（每个只有一部分数据）\n        * 不同partition可以存在不同的broker上\n        * 假如没有HA机制，一个节点挂了，数据就会丢失一部分\n\n\n\n* topic\n\t* 存储消息的一个逻辑概念\n    \t* 可认为是消息集合\n\n\n* HA机制（高可用机制）\n\t* kafka 0.8之后，提供了高可用机制\n    * replia副本机制\n    \t* 每个partition数据会同步到其他机器上，形成多个replia副本\n        \n        * 副本间会选举出一个leader，其他的为follower\n        \n        * 生产、消费都是跟leader打交道（其他不行），leader会同步数据到其他副本\n        \n        * 生产消费都是先全部同步成功，在返回ack给生产、消费者\n        \n    * 则一个节点挂了，数据还在，还能用\n    \t* 自动感知leader挂了，选举出新的leader","layout":null},"children":[]}]},{"data":{"id":"bxb99ohnf340","created":1569635278887,"text":"如何保证消费消息时的幂等性","note":"* 即防止重复消费\n\t* 加请求流水号\n    \t* 放进redis，使用setNX处理\n        * 提交事务之后删除\n        * 请求全部先检查缓存，再检查数据库 \n    * 数据库主键唯一限制\n\n* MQ是不保证消息只发一次的\n\n\n\n* kafka中\n\t* 每条消息都有一个offset\n    \t* 代表了消息的顺序的序号\n        * kafka根据消息进入的顺序进行分配的\n     \n    * 消费者从kafka消费的时候，是按照顺序去消费的 \n    \t* 消费者消费完会提交offset，即通知kafka已经消费该条消息\n        \n        * 基于zookeeper实现\n        * 提交offset不是实时的，是定时提交一次（所以已经消费了的，可能没提交offsset就重启了）\n        \n    * zookeeper会记录消费者当前消费到offset等于几的消息\n    \t* kafka能感知到该offset\n     ","layout":null},"children":[]},{"data":{"id":"bxba90ie7000","created":1569638047799,"text":"如何保证消息的可靠性传输","layout_right_offset":{"x":-1,"y":3},"layout":null,"note":"* 如何处理消息丢失问题\n\n\n\t","expandState":"collapse"},"children":[{"data":{"id":"bxbbp5r99kg0","created":1569642134155,"text":"生产者到MQ","expandState":"expand"},"children":[{"data":{"id":"bxbbghbai0g0","created":1569641454034,"text":"事务机制","note":"* rabbitMQ 支持事务\n\t* channel.txSelect()声明启动事务模式\n    * channel.txComment()提交事务\n    * channel.txRollback()回滚事务\n    \n    * 事务中发生异常可先回滚，再次发送消息\n    \n\n* 特点\n\t* 事务机制，是同步的\n    \t* 生产者发送消息会阻塞（等待响应结果）\n        * 影响吞吐量"},"children":[]},{"data":{"id":"bxbbj1vo5n40","created":1569641655530,"text":"确认机制","note":"* rabbitmq channel设置成confirm机制\n\t* 再发送消息\n    \n    * rabbitmq接收到消息之后\n    \t* 回调生产者，通知已经接收成功\n    * rabbitMq接收消息报错\n    \t* 回调接口，通知失败。生产者此时可选择再次重发\n        \n\n\t* 不阻塞，吞吐量高\n\n\n* kafka\n\t* 设置acks=all 也是确认机制"},"children":[]}]},{"data":{"id":"bxbbpy56jnc0","created":1569642195947,"text":"MQ数据丢失","note":"* rabbitMQ\n1. 创建queue时将其设置为持久化的\n\t* 将会持久化queue的元数据\n    \n2. 发送消息时设置deliveryMode为2\n\t* 消息持久化\n    \n* 可以结合确认机制\n\t* 持久化后才发送接收成功通知\n    \n\n* kafka\n1. leader宕机，部分数据没来得及同步到follower\n   * 数据丢失\n        \n2. 参数设置\n   * replication.factor大于1\n        * 即至少2副本（副本计算包括leader）\n        \n    * min.insync.replicas大于1\n        * 即leader感知到至少有一个follower跟自己保持联系\n        * 确保leader挂了还有一个follower\n        \n    * 在生产者端设置acks=all\n    \t* 即要求每条数据必须写入所有的replia后，才算是成功\n        \n    * 生产者端设置retries=很大的一个值\n    \t* 写入失败，无线重试\n        * 即上面的配置，至少2副本等条件，不满足也算是失败，会不断重试"},"children":[]},{"data":{"id":"bxbbufe2vx40","created":1569642546947,"text":"消费者丢失数据","layout_right_offset":{"x":7,"y":14},"note":"* rabbitmq设置了autoAck 自动通知mq\n\t* 才会出现\n    \n    * 一般要关掉\n    \t* rabbitmq会重发给其他消费者\n     \n     \n     \n* kafka\n\t* 跟rabbitmq差不多\n    \t* 设置了自动提交offset\n    * 改为手动提交即可"},"children":[]}]},{"data":{"id":"bxbgjwa9cbs0","created":1569655827265,"text":"如何保证消息的顺序性","note":"* 如mysql binlog同步\n\t* 顺序性必须保证\n\n* rabbitMQ\n\t* queue中，消息只能被消费一次\n    \t* 多消费者情况下，顺序性不能保证\n    * 解决\n    \t* 需要保证顺序性的数据，都一个队列对应一个消费者\n        \n\n* kafka\n\t* 写入一个partition的数据，一定是有顺序的\n    \t* 生产者写的时候，可以指定一个key（如订单id）\n        * 跟此订单相关的数据，一定分配到一个partition中\n        * 可使用hash进行分发\n    \n    * 一个partition只对应一个消费者\n    \t* 本来也做不到对应多个消费者\n    \t* 则可以保证顺序性\n        \n    * 消费者内部多线程处理\n    \t* 思路跟上面多个partition一样\n        * 再次进行hash分发，相同订单号的放进一个一个内存队列，一个线程对应一个内存队列\n        * 则可以保证顺序性\n     \n     * 单线程的消费者\n    \t* 一条需要几十ms的话，一秒处理几十条数据，吞吐量较低\n        * 所以一般还是多线程\n        \n        * 压测，4核8G的机器，单机开32线程，每秒可处理上千条数据"},"children":[]},{"data":{"id":"bxbi48jsytk0","created":1569660242357,"text":"消息队列满了怎么处理","note":"* 或者问：几百万数据积压怎么处理\n\t* 对于rabbitmq，可以设置过期时间\n\t\t* 时间长消息会丢失（因此不能这样设置）\n        * 如果已经发生，则写程序从数据源头重新导出，进行补偿\n\n\n* 消费端出现问题\n\t* 导致mq满了，或者大量积压。以及消息已经延迟等问题\n    \n* 处理\n\t* 当务之急，肯定是修复消费者 \n    \n    * 新加一个Topic（kafka），并且partition是原来的10倍\n    \t* 消费者消费到数据后，不执行原来的逻辑，而是重写写到新的topic\n        \n        * 新加机器，作为消费者去处理新的topic\n        \n\t* 如果mq满了，则要加新的临时mq处理\n    \t* 加不了那就扔掉数据，后续写程序进行补偿"},"children":[]},{"data":{"id":"bxbafics9gg0","created":1569638556827,"text":"项目场景","note":"* 账务系统放款\n\t* 账务方面计算费用，是比较耗时的 一个业务\n    \t* 做成异步\n        \n    * 同时账务系统对接多个贷前入口\n    \t* 解耦"},"children":[]},{"data":{"id":"bxbiwnbvr4g0","created":1569662468726,"text":"如何设计一个消息队列","note":"* 首先MQ需要支持扩容\n\t* 即可伸缩性\n    * 设计分布式系统，参考kafka\n    \t* 每个broker是一个机器，是集群的其中一个节点\n        * 一个topic可以拆成多个partition来存储\n        * 资源不够就增加partition（增加机器）\n        * 有需要的话还可以做数据迁移\n        \n* 其实考虑数据做持久化（落盘）\n\t* 保证数据不丢失\n    * 在磁盘做顺序写，性能会比随机写性能更好\n    \t\n        \n* 其次 考虑mq的可用性\n\t* 如kafaka的多副本的高可用保障机制\n    \n* 数据丢失问题处理\n\t* 确认机制等"},"children":[{"data":{"id":"bxbji7jgrxk0","created":1569664158368,"text":"关于顺序写和随机写","note":"* 随机和顺序读写，是存储器的两种输入输出方式。\n\t* 连续的磁盘，删除数据后留下空洞\n    \t* 读取这些不连续的空间的数据，就是随机写，速度慢\n        * 因为磁头要不断的调整磁道的位置，以在不同位置上的读写数据，\n    * 连续的磁盘进行读写，速度快"},"children":[]}]}]},{"data":{"id":"bxbjseo53sw0","created":1569664957529,"text":"redis","layout_right_offset":{"x":2,"y":4}},"children":[{"data":{"id":"bxbjzn6q3e80","created":1569665524616,"text":"为什么要用缓存","note":"* 高性能，高并发\n\n* 不变的数据，如系统配置、商品信息\n\t* 多人访问，每次从数据库获取，则浪费性能\n    \t* 存进缓存，速度快\n        \n    * 常用的复杂查询的结果也可以放进缓存\n    \n    \n        \n* 访问高峰期时（高并发）\n\t* 对数据库造成很大压力，可能宕机\n    \t* 使用缓存减轻压力\n \n \n \n* 缓存为什么快\n\t* 缓存是走内存的，天然速度快，能支撑高并发访问\n\t\t* 几万/s的访问也是没问题的\n\n\t* 数据库则不行\n\t\t* 一般建议并发不能超过2000/s\n        \n   "},"children":[]},{"data":{"id":"bxbm7rv5axk0","created":1569671803933,"text":"与mencache的区别","note":"* redis作者给出的比较\n\t1. 支持更多数据结构与操作\n    \n    2. 内存使用效率对比（不重要）\n    \t* 简单的key-value，是memcache高\n        * redis采用hash结构来做key-value的话，redis会更高\n        * 因为是组合式的压缩\n        \n    3. 性能（跟第二点一样，区别比较轻微，可不说）\n    \t* redis只是用单核（单线程）\n        \t* 平均到每个核上，redis在存储小数据时，性能比memcache高\n            * 100k以上的大数据，memcached性能高一些\n        * memcache可以使用多核\n    \n    4. memcached 没有原生的集群模式\n    \t* 依靠客户端实现分片（集群中分片写入数据）\n        * redis原生支持cluster模式(官方支持)"},"children":[]},{"data":{"id":"bxbm2zh3hcw0","created":1569671428677,"text":"redis的线程模型","note":"* 文件事件处理器（file event handler）\n\t* redis基于rector模式开发的网络事件处理器\n    * 是单线程的\n    \t* 采用IO多路复用机制同时监听多个socket\n        * 根据socket上的事件来选择对应的事件处理器处理这个事件\n     \n     \n\n* 文件事件处理器结构\n\t* 多个socket\n\n\t* IO多路复用程序\n\n\t* 文件事件分派器\n    \n    * 事件处理器\n    \t* 命令请求处理器\n        * 命令回复处理器\n        * 连接应答处理器\n        \n* redis单线程模型为啥效率高\n\t* 纯内存操作\n    * 核心是基于非阻塞的IO多路复用机制\n    \t* 由于不阻塞，效率高（相当于不等待，一直处理各种事情）\n        \n    * 单线程避免线程频繁上下切换\n    \t* 内核态、用户态切换耗性能\n\t"},"children":[]},{"data":{"id":"bxbmwjwq9ag0","created":1569673745719,"text":"客户端与redis的一次通信","note":"* 基于socket通信模型进行通信 \n\t* redis 中有一个server socket监听请求\n \n* redis启动\n\t* 会将AE_READABLE事件与连接应答处理器进行关联\n\n\n\n\n1. IO多路复用程序会监听socket\n    * 将监听到事件的socket（及其产生的事件）压到一个队列里面\n    \n    * 每次取出一个socket给事件分派器\n    \t* 处理完之后才拿下一个\n    \n    * 文件事件分派器会将队列里面的socket取出\n    \t* 交给对应的处理器进行处理\n        \n        \n\n\n\n\n"},"children":[{"data":{"id":"bxboek46s2g0","created":1569677977835,"text":"连接","note":"2. 例：客户端连接到redis的server socket，请求建立连接\n\t* server socket接收到请求后，会产生AE_READABLE事件\n        \n    * 第1点中的处理步骤\n        \n    * 最终交给连接应答处理器进行处理\n        * 连接应答处理器与客户端建立连接，创建客户端对应的socket（客户端本身有一个socket）\n        \n        * 将此socket的AE_READABLE事件与命令请求处理器关联"},"children":[]},{"data":{"id":"bxboerr4n3c0","created":1569677994459,"text":"请求","note":"3. 客户端发起写读写请求\n\t* 则已经建立连接的socket会产生AE_READABLE事件\n    \n    * 同样，IO多路复用程序处理\n    \t* 第一点\n        \n    * 交给命令请求处理器处理\n    \t* 从socket中读出请求的key，value（假设是写请求）\n        * 在内存中key，value的设置\n\t\n    \n* 处理完毕后（准备好响应数据后）\n    * 将socket的AE_WRITABLE事件跟命令回复处理器关联\n        \n    * 客户端准备好读取数据时，socket上会产生AE_WRITABLE事件\n    \n    * 同样，IO多路复用程序处理\n    \t* 最终交给命令回复处理器处理\n   \n    * 命令回复处理器对socket输出本次操作的一个结果\n    \n    * 将此socket与AE_WRITABLE事件解除关联\n        \n        "},"children":[]}]}]}]},"template":"right","theme":"fresh-green","version":"1.4.43"}